<a id="mulu">目录</a>
<a href="#mulu" class="back">回到目录</a>
<style>
    .back{width:40px;height:40px;display:inline-block;line-height:20px;font-size:20px;background-color:lightyellow;position: fixed;bottom:50px;right:50px;z-index:999;border:2px solid pink;opacity:0.3;transition:all 0.3s;color:green;}
    .back:hover{color:red;opacity:1}
    img{vertical-align:bottom;}
</style>

<!-- @import "[TOC]" {cmd="toc" depthFrom=3 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [比较检验](#比较检验)
    - [假设检验](#假设检验)
- [偏差与方差](#偏差与方差)

<!-- /code_chunk_output -->

<!-- 打开侧边预览：f1->Markdown Preview Enhanced: open...
只有打开侧边预览时保存才自动更新目录 -->

写在前面：此笔记来自[Vay-keen/Machine-learning-learning-notes](https://github.com/Vay-keen/Machine-learning-learning-notes)

### 比较检验
以“错误率”作为性能度量的标准
##### 假设检验
假设：对样本总体的分布或已知分布中某个参数值的一种猜想，例如：假设总体服从泊松分布，或假设正态总体的期望u=u0。具体来说，是对学习器泛化错误率分布的某种判断或猜想
在测量学习器的泛化错误率时，我们只能通过测试集获得测试错误率，但直观上测试错误率和泛化错误率相差不会太远，因此可以通过测试错误率来推测泛化错误率的分布，这就是一种假设检验
适用于对单个学习器泛化性能的假设进行检验
- **二项检验(binomial test)**：在α的显著度下，假设`ε≤ε0`不能被拒绝，即能以`1-α`的置信度认为，学习器的泛化错误率不大于ε0；否则该假设可被拒绝，即在α的显著度下可认为学习器的泛化错误率大于ε0
- **t检验(t-test)**：用于通过多次重复留出法或交叉验证法等进行多次训练/测试，从而得到多个测试误率的情况
    ![t检验](./md-image/t检验.png){:width=250 height=250}
    临界值：对假设`μ=ε0`和显著度α，当测试错误率均值为ε0时，在`1-α`概率内能观测到的最大错误率
    双边假设(two-tailed)：两边阴影部分各有α/2的面积，若平均错误率μ与ε0之差`|μ-ε0|`位于临界值范围[t~-α/2~, t~α/2~]内，则不能拒绝假设`μ=ε0`"，即可认为泛化错误率为ε0，置信度为1-α; 否则可拒绝该假设，即在该显著度下可认为泛化错误率与ε0有显著不同
    α常用取值有0.05和0.1

---

如果需要对多个学习器的性能进行比较
- **k折交叉验证成对t检验(paired t-tests)**：若两个学习器的性能相同，则它们使用相同的训练/测试集得到的测试错误率应相同
  - 先对每对结果求差，根据差值对"学习器A与B性能相同"这个假设做t检验，计算出差值的均值μ和方差σ^2^，在显著度α下，若变量![k折交叉验证成对t检验](./md-image/k折交叉验证成对t检验.png){:width=50 height=50}小于临界值t~α/2,k-1~，则假设不能被拒绝，即认为两个学习器的性能没有显著差别；否则认为有差别，且平均错误率较小的那个学习器性能较优
  - 5x2交叉验证：在每次2折交叉验证之前随机将数据打乱，使得5次交叉验证中的数据划分不重复。第i次2折交叉验证产生两对测试错误率，分别求差，得到第1折上的差值Δ^1^~i~和第2折的Δ^2^~i~；计算第1次2折交叉验证的两个结果的平均值μ=0.5(Δ^1^~i~+Δ^2^~i~)；对每次2折实验的结果都计算方差![5x2交叉验证](./md-image/5x2交叉验证.png){:width=50 height=30}。变量![5x2交叉验证2](./md-image/5x2交叉验证2.png){:width=60 height=60}服从自由度为5的t分布，双边检验临界值为t~α/2,5~
- **McNemar检验**：在二分类问题中，可得到两学习器分类结果的差别，如**列联表(contingency table)**
  ![列联表](./md-image/列联表.png){:width=150 height=150}
  假设是两学习器性能相同，则应有e~01~=e~10~，那么变量|e~01~-e~10~|应当服从正态分布，且均值为1，方差为e~01~+e~10~。变量![McNemar检验](./md-image/McNemar检验.png){:width=50 height=50}服从自由度为1的χ^2^分布（卡方分布），给定显著度α，当以上变量恒小于临界值χ^2^~α~时，不能拒绝假设，即认为两学习器的性能没有显著差别；否则认为有差别，且平均错误率较小的那个学习器性能较优
- Friedman检验与Nemenyi后续检验：对多个算法进行比较，前面的方法只能两两比较，而该方法基于算法排序
  - Friedman检验使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据测试性能由好到坏排序，并赋予序值1, 2, ...，若算法的测试性能相同，则平分序值
    ![算法比较序位表](./md-image/算法比较序位表.png){:width=150 height=150}
    使用Friedman检验来判断这些算法是否性能都相同：若相同，则它们的平均序值应当相同。一次使用卡方检验和F检验，判断“所有算法的性能相同”这个假设是否成立，若不成立，则需进行**后续检验(post-hoc test)**进一步区分各算法
  - **Nemenyi后续检验**：计算出平均序值差别的临界值域CD，若两个算法的平均序值之差超出了CD， 则以相应的置信度拒绝“两个算法性能相同”这一假设，两两判断算法的性能有无区别
  - **Friedman检验图**：纵轴显示各个算法，横轴是平均序值，圆点显示算法的平均序值，以圆点为中心的横线段表示临界值域的大小。若两个算法的横线段有交叠，则说明这两个算法没有显著差别，否则即说明有显著差别
    ![Friedman检验图](./md-image/Friedman检验图.png){:width=150 height=150}
    如图，算法A与B没有显著差别（横线段有交叠区域），而算法A显著优于算法C（没有交叠区域）
### 偏差与方差

偏差-方差分解是解释学习器泛化性能的重要工具。在学习算法中，偏差指的是预测的期望值与真实值的偏差，方差则是每一次预测值与预测值得期望之间的差均方。实际上，偏差体现了学习器预测的准确度，而方差体现了学习器预测的稳定性。通过对泛化误差的进行分解，可以得到：

 + **期望泛化误差=方差+偏差**	
 + **偏差刻画学习器的拟合能力**
 + **方差体现学习器的稳定性**

易知：方差和偏差具有矛盾性，这就是常说的偏差-方差窘境（bias-variance dilamma），随着训练程度的提升，期望预测值与真实值之间的差异越来越小，即偏差越来越小，但是另一方面，随着训练程度加大，学习算法对数据集的波动越来越敏感，方差值越来越大。换句话说：在欠拟合时，偏差主导泛化误差，而训练到一定程度后，偏差越来越小，方差主导了泛化误差。因此训练也不要贪杯，适度辄止。

![13.png](https://i.loli.net/2018/10/17/5bc722234b09f.png)

