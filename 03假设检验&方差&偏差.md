<a id="mulu">目录</a>
<a href="#mulu" class="back">回到目录</a>
<style>
    .back{width:40px;height:40px;display:inline-block;line-height:20px;font-size:20px;background-color:lightyellow;position: fixed;bottom:50px;right:50px;z-index:999;border:2px solid pink;opacity:0.3;transition:all 0.3s;color:green;}
    .back:hover{color:red;opacity:1}
    img{vertical-align:bottom;}
</style>

<!-- @import "[TOC]" {cmd="toc" depthFrom=3 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [比较检验](#比较检验)
    - [假设检验](#假设检验)

<!-- /code_chunk_output -->

<!-- 打开侧边预览：f1->Markdown Preview Enhanced: open...
只有打开侧边预览时保存才自动更新目录 -->

写在前面：此笔记来自[Vay-keen/Machine-learning-learning-notes](https://github.com/Vay-keen/Machine-learning-learning-notes)

### 比较检验
以“错误率”作为性能度量的标准
##### 假设检验
假设：对样本总体的分布或已知分布中某个参数值的一种猜想，例如：假设总体服从泊松分布，或假设正态总体的期望u=u0。具体来说，是对学习器泛化错误率分布的某种判断或猜想
在测量学习器的泛化错误率时，我们只能通过测试集获得测试错误率，但直观上测试错误率和泛化错误率相差不会太远，因此可以通过测试错误率来推测泛化错误率的分布，这就是一种假设检验
适用于对单个学习器泛化性能的假设进行检验
- **二项检验(binomial test)**：在α的显著度下，假设`ε≤ε0`不能被拒绝，即能以`1-α`的置信度认为，学习器的泛化错误率不大于ε0；否则该假设可被拒绝，即在α的显著度下可认为学习器的泛化错误率大于ε0
- **t检验(t-test)**：用于通过多次重复留出法或交叉验证法等进行多次训练/测试，从而得到多个测试误率的情况
    ![t检验](./md-image/t检验.png){:width=250 height=250}
    临界值：对假设`μ=ε0`和显著度α，当测试错误率均值为ε0时，在`1-α`概率内能观测到的最大错误率
    双边假设(two-tailed)：两边阴影部分各有α/2的面积，若平均错误率μ与ε0之差`|μ-ε0|`位于临界值范围[t~-α/2~, t~α/2~]内，则不能拒绝假设`μ=ε0`"，即可认为泛化错误率为ε0，置信度为1-α; 否则可拒绝该假设，即在该显著度下可认为泛化错误率与ε0有显著不同
    α常用取值有0.05和0.1

---


##**2.7 偏差与方差**

偏差-方差分解是解释学习器泛化性能的重要工具。在学习算法中，偏差指的是预测的期望值与真实值的偏差，方差则是每一次预测值与预测值得期望之间的差均方。实际上，偏差体现了学习器预测的准确度，而方差体现了学习器预测的稳定性。通过对泛化误差的进行分解，可以得到：

 + **期望泛化误差=方差+偏差**	
 + **偏差刻画学习器的拟合能力**
 + **方差体现学习器的稳定性**

易知：方差和偏差具有矛盾性，这就是常说的偏差-方差窘境（bias-variance dilamma），随着训练程度的提升，期望预测值与真实值之间的差异越来越小，即偏差越来越小，但是另一方面，随着训练程度加大，学习算法对数据集的波动越来越敏感，方差值越来越大。换句话说：在欠拟合时，偏差主导泛化误差，而训练到一定程度后，偏差越来越小，方差主导了泛化误差。因此训练也不要贪杯，适度辄止。

![13.png](https://i.loli.net/2018/10/17/5bc722234b09f.png)

